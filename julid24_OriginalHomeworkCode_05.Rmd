---
title: "julid24_OriginalHomeworkCode_05"
author: "Julianna D."
date: "`r Sys.Date()`"
output: 
  html_document:
    theme: cerulean
    toc: yes
    toc_float: true
---
```{r}
library(curl)
data <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv")
kc <- read.csv(data, header = TRUE, stringsAsFactors = FALSE)
attach(kc)
```

# Problem 1 Beta Coefficients
> Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

```{r}
# Fit the model
# x = log(Body_mass_female_mean)
# y = log(HomeRange_km2)
kc_fit <- lm(log(HomeRange_km2)~log(Body_mass_female_mean))
coef(kc_fit)
```

# Problem 2
>Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.

```{r}
# Bootstrapping for β coefficients
# reference source: https://www.statmethods.net/advstats/bootstrapping.html 
library(boot)
data <- data.frame(kc)

reg_boot <- function(data, idx) {
  fit <- lm(log(HomeRange_km2)~log(Body_mass_female_mean), data=data[idx, ])
  coef(fit)
} 

b <- boot(data, reg_boot, 1000)
b_coefs <- b$t
print(b_coefs)
# not entirely sure if this is right but I tried so many other things that didn't work and this kinda looks like it worked.
```

> Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

```{r}
se_b <- apply(b_coefs, 2, sd)
print(se_b)

ci_b <- boot.ci(b, index=1, type="perc")
print(ci_b)
```

> How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?

> Answer: They are pretty close in number. The SE from the entire dataset is slightly greater than the SE from the bootstrap data.

```{r}
# SE estimated from entire dataset
se_data <- summary(kc_fit)
se_data

# SE from bootstrap data
se_b <- apply(b_coefs, 2, sd)
print(se_b)
```

> How does the latter compare to the 95% CI estimated from your entire dataset?

> Answer: They are pretty close in number.

```{r}
# CI from entire dataset
CI_data <- confint(kc_fit)
CI_data

# CI from bootstrap data
ci_b <- boot.ci(b, index=1, type="perc")
print(ci_b)
```


# Extra Credit
> Write a FUNCTION that takes as its arguments a dataframe, “d”, a linear model, “m” (as a character string, e.g., “logHR~logBM”), a user-defined confidence interval level, “conf.level” (with default = 0.95), and a number of bootstrap replicates, “n” (with default = 1000). Your function should return a dataframe that includes: beta coefficient names; beta coefficients, standard errors, and upper and lower CI limits for the linear model based on your entire dataset; and mean beta coefficient estimates, SEs, and CI limits for those coefficients based on your bootstrap.


# Extra Extra Credit
> Graph each beta value from the linear model and its corresponding mean value, lower CI and upper CI from a bootstrap as a function of number of bootstraps from 10 to 200 by 10s. HINT: the beta value from the linear model will be the same for all bootstraps and the mean beta value may not differ that much!
